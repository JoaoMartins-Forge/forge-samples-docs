"use strict";(self.webpackChunkforge_samples_docs=self.webpackChunkforge_samples_docs||[]).push([[822],{3905:function(e,t,n){n.d(t,{Zo:function(){return c},kt:function(){return m}});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},i=Object.keys(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var l=r.createContext({}),u=function(e){var t=r.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},c=function(e){var t=u(e.components);return r.createElement(l.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},d=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),d=u(n),m=a,f=d["".concat(l,".").concat(m)]||d[m]||p[m]||i;return n?r.createElement(f,o(o({ref:t},c),{},{components:n})):r.createElement(f,o({ref:t},c))}));function m(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,o=new Array(i);o[0]=d;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:a,o[1]=s;for(var u=2;u<i;u++)o[u]=n[u];return r.createElement.apply(null,o)}return r.createElement.apply(null,n)}d.displayName="MDXCreateElement"},8401:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return s},contentTitle:function(){return l},metadata:function(){return u},toc:function(){return c},default:function(){return d}});var r=n(7462),a=n(3366),i=(n(7294),n(3905)),o=["components"],s={sidebar_position:3},l="Data Management",u={unversionedId:"tutorials/simple-viewer/nodejs/data-management",id:"tutorials/simple-viewer/nodejs/data-management",isDocsHomePage:!1,title:"Data Management",description:"Next, let's extend our server so that we can list models, upload them, and also initiate",source:"@site/docs/tutorials/simple-viewer/nodejs/data-management.md",sourceDirName:"tutorials/simple-viewer/nodejs",slug:"/tutorials/simple-viewer/nodejs/data-management",permalink:"/forge-samples-docs/docs/tutorials/simple-viewer/nodejs/data-management",editUrl:"https://github.com/petrbroz/forge-samples-docs/edit/main/website/docs/tutorials/simple-viewer/nodejs/data-management.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Authentication",permalink:"/forge-samples-docs/docs/tutorials/simple-viewer/nodejs/authentication"},next:{title:"Viewer",permalink:"/forge-samples-docs/docs/tutorials/simple-viewer/nodejs/viewer"}},c=[{value:"Preparing a bucket",id:"preparing-a-bucket",children:[]},{value:"Listing models",id:"listing-models",children:[]},{value:"Uploading and translating models",id:"uploading-and-translating-models",children:[]},{value:"Server endpoints",id:"server-endpoints",children:[]},{value:"Try it out",id:"try-it-out",children:[]}],p={toc:c};function d(e){var t=e.components,s=(0,a.Z)(e,o);return(0,i.kt)("wrapper",(0,r.Z)({},p,s,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"data-management"},"Data Management"),(0,i.kt)("p",null,"Next, let's extend our server so that we can list models, upload them, and also initiate\ntheir translation for viewing."),(0,i.kt)("h2",{id:"preparing-a-bucket"},"Preparing a bucket"),(0,i.kt)("p",null,"First, let's make sure that our application has a bucket in the Data Management service\nto store its files in. Typically the bucket would be created just once as part of a provisioning\nstep but in our sample we will implement a helper function that will make sure that the bucket\nis available. Let's update the ",(0,i.kt)("inlineCode",{parentName:"p"},"services/forge.js")," file:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-js",metastring:'{1,8,29-40} title="services/forge.js"',"{1,8,29-40}":!0,title:'"services/forge.js"'},"const { AuthClientTwoLegged, BucketsApi } = require('forge-apis');\n\nconst { FORGE_CLIENT_ID, FORGE_CLIENT_SECRET, FORGE_BUCKET } = process.env;\nif (!FORGE_CLIENT_ID || !FORGE_CLIENT_SECRET) {\n    console.warn('Missing some of the environment variables.');\n    process.exit(1);\n}\nconst BUCKET = FORGE_BUCKET || `${FORGE_CLIENT_ID.toLowerCase()}-basic-app`;\nconst INTERNAL_TOKEN_SCOPES = ['bucket:read', 'bucket:create', 'data:read', 'data:write', 'data:create'];\nconst PUBLIC_TOKEN_SCOPES = ['viewables:read'];\n\nlet internalAuthClient = new AuthClientTwoLegged(FORGE_CLIENT_ID, FORGE_CLIENT_SECRET, INTERNAL_TOKEN_SCOPES, true);\nlet publicAuthClient = new AuthClientTwoLegged(FORGE_CLIENT_ID, FORGE_CLIENT_SECRET, PUBLIC_TOKEN_SCOPES, true);\n\nasync function getInternalToken() {\n    if (!internalAuthClient.isAuthorized()) {\n        await internalAuthClient.authenticate();\n    }\n    return internalAuthClient.getCredentials();\n}\n\nasync function getPublicToken() {\n    if (!publicAuthClient.isAuthorized()) {\n        await publicAuthClient.authenticate();\n    }\n    return publicAuthClient.getCredentials();\n}\n\nasync function ensureBucketExists() {\n    const token = await getInternalToken();\n    try {\n        await new BucketsApi().getBucketDetails(BUCKET, null, token);\n    } catch (err) {\n        if (err.statusCode === 404) {\n            await new BucketsApi().createBucket({ bucketKey: BUCKET, policyKey: 'temporary' }, {}, null, token);\n        } else {\n            throw err;\n        }\n    }\n}\n\nmodule.exports = {\n    getPublicToken\n};\n")),(0,i.kt)("p",null,"The ",(0,i.kt)("inlineCode",{parentName:"p"},"ensureBucketExists")," function will simply try and request additional information\nabout a specific bucket, and if the response from Forge is ",(0,i.kt)("inlineCode",{parentName:"p"},"404 Not Found"),", it will\nattempt to create a new bucket of that name."),(0,i.kt)("h2",{id:"listing-models"},"Listing models"),(0,i.kt)("p",null,"Now we will update the ",(0,i.kt)("inlineCode",{parentName:"p"},"services/forge.js")," script with a helper function that will\nlist all objects in the preconfigured bucket:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-js",metastring:'{1,15,44-58,62} title="services/forge.js"',"{1,15,44-58,62}":!0,title:'"services/forge.js"'},"const { AuthClientTwoLegged, BucketsApi, ObjectsApi } = require('forge-apis');\n\nconst { FORGE_CLIENT_ID, FORGE_CLIENT_SECRET, FORGE_BUCKET } = process.env;\nconst { FORGE_CLIENT_ID, FORGE_CLIENT_SECRET } = process.env;\nif (!FORGE_CLIENT_ID || !FORGE_CLIENT_SECRET) {\n    console.warn('Missing some of the environment variables.');\n    process.exit(1);\n}\nconst INTERNAL_TOKEN_SCOPES = ['bucket:read', 'bucket:create', 'data:read', 'data:write', 'data:create'];\nconst PUBLIC_TOKEN_SCOPES = ['viewables:read'];\n\nlet internalAuthClient = new AuthClientTwoLegged(FORGE_CLIENT_ID, FORGE_CLIENT_SECRET, INTERNAL_TOKEN_SCOPES, true);\nlet publicAuthClient = new AuthClientTwoLegged(FORGE_CLIENT_ID, FORGE_CLIENT_SECRET, PUBLIC_TOKEN_SCOPES, true);\n\nconst urnify = (id) => Buffer.from(id).toString('base64').replace(/=/g, '');\n\nasync function getInternalToken() {\n    if (!internalAuthClient.isAuthorized()) {\n        await internalAuthClient.authenticate();\n    }\n    return internalAuthClient.getCredentials();\n}\n\nasync function getPublicToken() {\n    if (!publicAuthClient.isAuthorized()) {\n        await publicAuthClient.authenticate();\n    }\n    return publicAuthClient.getCredentials();\n}\n\nasync function ensureBucketExists() {\n    const token = await getInternalToken();\n    try {\n        await new BucketsApi().getBucketDetails(BUCKET, null, token);\n    } catch (err) {\n        if (err.statusCode === 404) {\n            await new BucketsApi().createBucket({ bucketKey: BUCKET, policyKey: 'temporary' }, {}, null, token);\n        } else {\n            throw err;\n        }\n    }\n}\n\nasync function listModels() {\n    await ensureBucketExists(); // Remove this if we can assume the bucket to exist\n    const token = await getInternalToken();\n    let response = await new ObjectsApi().getObjects(BUCKET, { limit: 64 }, null, token);\n    let objects = response.body.items;\n    while (response.body.next) {\n        const startAt = new URL(response.body.next).searchParams.get('startAt');\n        response = await new ObjectsApi().getObjects(BUCKET, { limit: 64, startAt }, null, token);\n        objects = objects.concat(response.body.items);\n    }\n    return objects.map(obj => ({\n        name: obj.objectKey,\n        urn: urnify(obj.objectId)\n    }));\n}\n\nmodule.exports = {\n    getPublicToken,\n    listModels\n};\n")),(0,i.kt)("p",null,"The ",(0,i.kt)("inlineCode",{parentName:"p"},"listModels")," function pages through all objects in the bucket, and returns their name and URN\n(the base64-encoded ID that will later be used when communicating with the Model Derivative service)."),(0,i.kt)("h2",{id:"uploading-and-translating-models"},"Uploading and translating models"),(0,i.kt)("p",null,"The last helper function we add to ",(0,i.kt)("inlineCode",{parentName:"p"},"services/forge.js")," will handle the uploading of a file\nto the Data Management service, and its translation into a format that can later be loaded into\nForge Viewer:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-js",metastring:'{1,2,61-79,84} title="services/forge.js"',"{1,2,61-79,84}":!0,title:'"services/forge.js"'},"const fs = require('fs');\nconst { AuthClientTwoLegged, BucketsApi, ObjectsApi, DerivativesApi } = require('forge-apis');\n\nconst { FORGE_CLIENT_ID, FORGE_CLIENT_SECRET, FORGE_BUCKET } = process.env;\nif (!FORGE_CLIENT_ID || !FORGE_CLIENT_SECRET) {\n    console.warn('Missing some of the environment variables.');\n    process.exit(1);\n}\nconst BUCKET = FORGE_BUCKET || `${FORGE_CLIENT_ID.toLowerCase()}-basic-app`;\nconst INTERNAL_TOKEN_SCOPES = ['bucket:read', 'bucket:create', 'data:read', 'data:write', 'data:create'];\nconst PUBLIC_TOKEN_SCOPES = ['viewables:read'];\n\nlet internalAuthClient = new AuthClientTwoLegged(FORGE_CLIENT_ID, FORGE_CLIENT_SECRET, INTERNAL_TOKEN_SCOPES, true);\nlet publicAuthClient = new AuthClientTwoLegged(FORGE_CLIENT_ID, FORGE_CLIENT_SECRET, PUBLIC_TOKEN_SCOPES, true);\n\nconst urnify = (id) => Buffer.from(id).toString('base64').replace(/=/g, '');\n\nasync function getInternalToken() {\n    if (!internalAuthClient.isAuthorized()) {\n        await internalAuthClient.authenticate();\n    }\n    return internalAuthClient.getCredentials();\n}\n\nasync function getPublicToken() {\n    if (!publicAuthClient.isAuthorized()) {\n        await publicAuthClient.authenticate();\n    }\n    return publicAuthClient.getCredentials();\n}\n\nasync function ensureBucketExists() {\n    const token = await getInternalToken();\n    try {\n        await new BucketsApi().getBucketDetails(BUCKET, null, token);\n    } catch (err) {\n        if (err.statusCode === 404) {\n            await new BucketsApi().createBucket({ bucketKey: BUCKET, policyKey: 'temporary' }, {}, null, token);\n        } else {\n            throw err;\n        }\n    }\n}\n\nasync function listModels() {\n    await ensureBucketExists(); // Remove this if we can assume the bucket to exist\n    const token = await getInternalToken();\n    let response = await new ObjectsApi().getObjects(BUCKET, { limit: 64 }, null, token);\n    let objects = response.body.items;\n    while (response.body.next) {\n        const startAt = new URL(response.body.next).searchParams.get('startAt');\n        response = await new ObjectsApi().getObjects(BUCKET, { limit: 64, startAt }, null, token);\n        objects = objects.concat(response.body.items);\n    }\n    return objects.map(obj => ({\n        name: obj.objectKey,\n        urn: urnify(obj.objectId)\n    }));\n}\n\nasync function uploadModel(objectName, filePath, rootFilename) {\n    await ensureBucketExists(); // Remove this if we can assume the bucket to exist\n    const token = await getInternalToken();\n    const buffer = fs.readFileSync(filePath);\n    const response = await new ObjectsApi().uploadObject(BUCKET, objectName, buffer.byteLength, buffer, {}, null, token);\n    const job = {\n        input: {\n            urn: urnify(response.body.objectId)\n        },\n        output: {\n            formats: [{ type: 'svf', views: ['2d', '3d'] }]\n        }\n    };\n    if (rootFilename) {\n        job.input.compressedUrn = true;\n        job.input.rootFilename = rootFilename;\n    }\n    await new DerivativesApi().translate(job, {}, null, token);\n}\n\nmodule.exports = {\n    getPublicToken,\n    listModels,\n    uploadModel\n};\n")),(0,i.kt)("h2",{id:"server-endpoints"},"Server endpoints"),(0,i.kt)("p",null,"Finally, let's make the functionality available to the client-side code through another\nExpress router. Create a ",(0,i.kt)("inlineCode",{parentName:"p"},"models.js")," file under the ",(0,i.kt)("inlineCode",{parentName:"p"},"routes")," subfolder with the following\ncontent:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-js",metastring:'title="routes/models.js"',title:'"routes/models.js"'},"const express = require('express');\nconst formidable = require('express-formidable');\nconst { listModels, uploadModel } = require('../services/forge.js');\n\nlet router = express.Router();\n\nrouter.get('/', async function (req, res, next) {\n    try {\n        res.json(await listModels());\n    } catch (err) {\n        next(err);\n    }\n});\n\nrouter.post('/', formidable(), async function (req, res, next) {\n    const file = req.files['model-file'];\n    if (!file) {\n        res.status(400).send('The required field (\"model-file\") is missing.');\n        return;\n    }\n    try {\n        await uploadModel(file.name, file.path, req.fields['model-zip-entrypoint']);\n        res.status(200).end();\n    } catch (err) {\n        next(err);\n    }\n});\n\nmodule.exports = router;\n")),(0,i.kt)("p",null,"The router will handle two types of requests - a ",(0,i.kt)("inlineCode",{parentName:"p"},"GET")," request when the client wants\nto get the list of all available models for viewing, and a ",(0,i.kt)("inlineCode",{parentName:"p"},"POST")," request when the client\nwants to upload a new model and translate it for viewing. The ",(0,i.kt)("inlineCode",{parentName:"p"},"formidable()")," middleware\nused in the ",(0,i.kt)("inlineCode",{parentName:"p"},"POST")," request handler will make sure that any ",(0,i.kt)("inlineCode",{parentName:"p"},"multipart/form-data")," content\ncoming with the request is parsed and available in the ",(0,i.kt)("inlineCode",{parentName:"p"},"req.files")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"req.fields")," properties."),(0,i.kt)("p",null,"Next, let's mount the router to our server application by modifying the ",(0,i.kt)("inlineCode",{parentName:"p"},"server.js"),":"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-js",metastring:'{7} title="server.js"',"{7}":!0,title:'"server.js"'},"const express = require('express');\nconst PORT = process.env.PORT || 3000;\n\nlet app = express();\napp.use(express.static('public'));\napp.use('/api/auth', require('./routes/auth.js'));\napp.use('/api/models', require('./routes/models.js'));\napp.use(function (err, req, res, next) {\n    console.error(err);\n    res.status(500).send(err.message);\n});\napp.listen(PORT, function () { console.log(`Server listening on port ${PORT}...`); });\n")),(0,i.kt)("p",null,"As you can see, the new router will handle ",(0,i.kt)("inlineCode",{parentName:"p"},"GET")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"POST")," requests coming to the endpoint\n",(0,i.kt)("inlineCode",{parentName:"p"},"/api/models"),"."),(0,i.kt)("h2",{id:"try-it-out"},"Try it out"),(0,i.kt)("p",null,"Time to try our improved server application. This time, apart from setting the Forge application\ncredentials, you can also include the name of the Data Management bucket you want to use via\nthe optional ",(0,i.kt)("inlineCode",{parentName:"p"},"FORGE_BUCKET")," environment variable:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"export FORGE_CLIENT_ID=your-own-forge-client-id\nexport FORGE_CLIENT_SECRET=your-own-forge-client-secret\nexport FORGE_BUCKET=your-custom-bucket-name\nnpm start\n")),(0,i.kt)("p",null,"If the bucket name is ",(0,i.kt)("em",{parentName:"p"},"not")," provided, the code in ",(0,i.kt)("inlineCode",{parentName:"p"},"services/forge.js")," will generate one by appending ",(0,i.kt)("inlineCode",{parentName:"p"},"-basic-app"),"\nto your Forge client ID."),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"Note that the Data Management service requires bucket names to be ",(0,i.kt)("strong",{parentName:"p"},"globally unique"),",\nand attempts to create a bucket with an already used name will fail with ",(0,i.kt)("inlineCode",{parentName:"p"},"409 Conflict"),".\nSee the ",(0,i.kt)("a",{parentName:"p",href:"https://forge.autodesk.com/en/docs/data/v2/reference/http/buckets-POST"},"documentation"),"\nfor more details.")),(0,i.kt)("p",null,"When you navigate to http://localhost:3000/api/models in the browser, the server should respond with\na JSON list with names and URNs of all objects available in your configured bucket."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Server Response",src:n(3173).Z})))}d.isMDXComponent=!0},3173:function(e,t,n){t.Z=n.p+"assets/images/data-response-cce1fea845b378ecf43feba0ea396c36.png"}}]);